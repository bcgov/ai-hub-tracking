name: .Terraform Deployer

on:
  workflow_call:
    inputs:
      environment_name:
        description: "The name of the environment to deploy to"
        required: true
        default: "tools"
        type: string
      command:
        description: "The Terraform command to run (init, plan, apply, destroy)"
        required: true
        default: "apply"
        type: string
      proxy_url:
        description: "The proxy URL to use for the secure tunnel"
        required: true
        type: string
      proxy_auth:
        description: "The proxy authentication token for the secure tunnel"
        required: true
        type: string
      tag:
        description: "The container tag to use for deployment"
        required: false
        type: string
      terraform_log_level:
        description: "The Terraform logging level"
        required: false
        default: "ERROR"
        type: string
    outputs:
      plan_comment:
        description: "Formatted Terraform plan summary markdown for PR comments"
        value: ${{ jobs.terraform.outputs.plan_comment }}
      plan_has_changes:
        description: "Whether Terraform plan contains infrastructure changes"
        value: ${{ jobs.terraform.outputs.plan_has_changes }}
env:
  TF_VERSION: 1.12.2
  TF_LOG: ${{ inputs.terraform_log_level }}
  CHISEL_IMAGE_VERSION: 1.11
  CHISEL_IMAGE: jpillora/chisel
permissions:
  id-token: write # Required for OIDC authentication
  contents: write

jobs:
  validate:
    name: Validate
    runs-on: ubuntu-24.04
    steps:
      - name: Check Environment Name
        run: |
          VALID_ENVS=("dev" "test" "prod")
          if [[ ! " ${VALID_ENVS[@]} " =~ " ${{ inputs.environment_name }} " ]]; then
            echo "Error: Invalid environment name '${{ inputs.environment_name }}'. Valid options are: ${VALID_ENVS[*]}"
            exit 1
          fi
          # check that proxy_url and proxy_auth are non-empty
          if [[ -z "${{ inputs.proxy_url }}" || -z "${{ inputs.proxy_auth }}" ]]; then
            echo "Error: proxy_url and proxy_auth are required inputs."
            exit 1
          fi

  terraform:
    environment: ${{ inputs.environment_name }}
    name: Terraform ${{ inputs.command }} via Secure Tunnel
    concurrency:
      cancel-in-progress: false
      group: ${{ inputs.environment_name }}
    needs: validate
    runs-on: ubuntu-24.04
    outputs:
      plan_comment: ${{ steps.plan_summary.outputs.plan_comment }}
      plan_has_changes: ${{ steps.plan_summary.outputs.has_changes }}
    steps:
      - name: Checkout
        uses: actions/checkout@v6

      - name: Azure CLI Login (OIDC)
        uses: azure/login@v2
        with:
          client-id: ${{ secrets.AZURE_CLIENT_ID }}
          tenant-id: ${{ secrets.AZURE_TENANT_ID }}
          subscription-id: ${{ secrets.AZURE_SUBSCRIPTION_ID }}

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: ${{ env.TF_VERSION }}
      - name: Run proxy client
        shell: bash
        run: |
          set -euo pipefail

          if [[ -z "${{ inputs.proxy_url }}" || -z "${{ inputs.proxy_auth }}" ]]; then
            echo "proxy_url and proxy_auth are required when use_secure_tunnel=true" >&2
            exit 1
          fi

          # Decode the proxy_url and proxy_auth.
          # Use loopback pinentry to avoid hangs; force stdout output to avoid "handle plaintext failed".
          KEY='${{ secrets.GPG_PASSPHRASE }}'
          if [[ -z "$KEY" ]]; then
            echo "GPG_PASSPHRASE secret is empty/missing" >&2
            exit 1
          fi

          decrypt_b64_gpg() {
            local encoded="$1"
            printf '%s' "$encoded" \
              | tr -d '\r\n' \
              | base64 --decode \
              | gpg --batch --yes --pinentry-mode loopback --passphrase "$KEY" --decrypt --output -
          }

          PROXY_URL="$(decrypt_b64_gpg '${{ inputs.proxy_url }}')"
          PROXY_AUTH="$(decrypt_b64_gpg '${{ inputs.proxy_auth }}')"
          echo "Proxy URL: ****${PROXY_URL: -4}"
          echo "Proxy Auth: ****${PROXY_AUTH: -4}"
          docker network create proxy-net >/dev/null 2>&1 || true
          docker run -d --name chisel-client --network proxy-net ${CHISEL_IMAGE}:${CHISEL_IMAGE_VERSION} client --auth "$PROXY_AUTH" "$PROXY_URL" 0.0.0.0:1080:socks
          docker run -d --name privoxy --network proxy-net -p 127.0.0.1:8118:8118 -e SOCKS_HOST=chisel-client -e SOCKS_PORT=1080 ghcr.io/${{ github.repository }}/azure-proxy/privoxy:${{inputs.tag || 'latest'}}
          docker logs chisel-client
          docker logs privoxy
          curl --proxy http://127.0.0.1:8118 https://ifconfig.me
      - name: Execute Deployment
        id: execute_deployment
        shell: bash
        working-directory: ./infra-ai-hub
        env:
          ARM_USE_OIDC: "true"
          CI: "true" # Common Terraform variables
          TF_VAR_app_name: "ai-services-hub"
          TF_VAR_app_env: ${{ inputs.environment_name }}
          TF_VAR_location: "Canada Central"
          TF_VAR_resource_group_name: ${{ format('{0}-{1}', 'ai-services-hub', inputs.environment_name) }}
          TF_VAR_common_tags: >-
            {"environment":"${{ inputs.environment_name }}","app_env":"${{ inputs.environment_name }}","repo_name":"${{ github.event.repository.name }}"}
          TF_VAR_subscription_id: ${{ secrets.AZURE_SUBSCRIPTION_ID }}
          TF_VAR_tenant_id: ${{ secrets.AZURE_TENANT_ID }}
          TF_VAR_client_id: ${{ secrets.AZURE_CLIENT_ID }}

          # Network-related variables (used by different modes)
          TF_VAR_vnet_name: ${{ secrets.VNET_NAME }}
          TF_VAR_vnet_resource_group_name: ${{ secrets.VNET_RESOURCE_GROUP_NAME }}
          TF_VAR_vnet_address_space: ${{ secrets.VNET_ADDRESS_SPACE }}
          TF_VAR_dev_address_spaces: ${{ secrets.DEV_ADDRESS_SPACES }}
          TF_VAR_test_address_spaces: ${{ secrets.TEST_ADDRESS_SPACES }}
          TF_VAR_prod_address_spaces: ${{ secrets.PROD_ADDRESS_SPACES }}
          TF_VAR_target_vnet_address_spaces: ${{ secrets.TARGET_VNET_ADDRESS_SPACES }}
          TF_VAR_source_vnet_address_space: ${{ secrets.SOURCE_VNET_ADDRESS_SPACE }}

          # Only used by infra-ai-hub, harmless if unset/unused
          TF_VAR_key_vault_name: ${{ format('{0}{1}{2}kv', 'aihub', inputs.environment_name, vars.SUBSCRIPTION_NAME) }}

          # Backend configuration for deploy script
          BACKEND_RESOURCE_GROUP: ${{ secrets.VNET_RESOURCE_GROUP_NAME }}
          BACKEND_STORAGE_ACCOUNT: ${{ vars.STORAGE_ACCOUNT_NAME }}

          HTTP_PROXY: "http://127.0.0.1:8118"
          HTTPS_PROXY: "http://127.0.0.1:8118"
          # Bypass proxy for Azure control plane APIs and Terraform registries; data plane uses proxy for private endpoint access
          NO_PROXY: "management.azure.com,login.microsoftonline.com,graph.microsoft.com,registry.terraform.io,releases.hashicorp.com,github.com,objects.githubusercontent.com"
        run: |
          set -euo pipefail

          export no_proxy="$NO_PROXY"

          # Make all scripts executable
          chmod +x ./scripts/*.sh

          LOG_FILE="$RUNNER_TEMP/terraform-${{ inputs.environment_name }}-${{ inputs.command }}.log"

          # Run deployment via script
          ./scripts/deploy-terraform.sh "${{ inputs.command }}" "${{ inputs.environment_name }}" 2>&1 | tee "$LOG_FILE"

          echo "log_file=$LOG_FILE" >> "$GITHUB_OUTPUT"

      - name: Build plan summary output
        id: plan_summary
        if: inputs.command == 'plan'
        shell: bash
        run: |
          set -euo pipefail

          NO_CHANGE_TEXT="No Changes to AI Hub Infra in this PR"
          LOG_FILE="${{ steps.execute_deployment.outputs.log_file }}"
          # check if log file exists
          if [[ -z "$LOG_FILE" || ! -f "$LOG_FILE" ]]; then
            echo "Log File Does Not Exist, cannot build plan summary. $LOG_FILE"
          fi
          echo "Log File Exist $LOG_FILE, moving to next step"
          # Create a cleaned copy of the log with ANSI escape sequences removed
          CLEAN_LOG="${LOG_FILE}.clean"
          if [[ -n "$LOG_FILE" && -f "$LOG_FILE" ]]; then
            # Remove common ANSI escape sequences to avoid grep misses
            sed -r 's/\x1B\[[0-9;]*[a-zA-Z]//g' "$LOG_FILE" > "$CLEAN_LOG" || cp "$LOG_FILE" "$CLEAN_LOG"
          else
            CLEAN_LOG="$LOG_FILE"
          fi
          echo "Clean log file created at $CLEAN_LOG"

          if [[ -z "$LOG_FILE" || ! -f "$LOG_FILE" ]]; then
            echo "has_changes=unknown" >> "$GITHUB_OUTPUT"
            {
              echo "plan_comment<<EOF"
              echo "Plan output was not found in logs for this run."
              echo "EOF"
            } >> "$GITHUB_OUTPUT"
            exit 0
          fi

          # The deploy script runs plan across multiple stacks (shared, tenant,
          # foundry, apim, tenant-user-mgmt). Each stack independently prints
          # either "No changes." or "Plan: N to add, N to change, N to destroy."
          # We must check ALL stacks — a single "No changes" does not mean the
          # whole plan is clean.

          # Collect all Plan summary lines (only lines with actual changes)
          PLAN_LINES=$(grep -E "^[[:space:]]*Plan: [0-9]+ to add, [0-9]+ to change, [0-9]+ to destroy\." "$CLEAN_LOG" || true)

          if [[ -z "$PLAN_LINES" ]]; then
            # No Plan lines found — either all stacks reported "No changes"
            # or the plan output format was unexpected
            if grep -q "No changes\." "$CLEAN_LOG"; then
              echo "has_changes=false" >> "$GITHUB_OUTPUT"
              {
                echo "plan_comment<<EOF"
                echo "$NO_CHANGE_TEXT"
                echo "EOF"
              } >> "$GITHUB_OUTPUT"
            else
              echo "has_changes=unknown" >> "$GITHUB_OUTPUT"
              {
                echo "plan_comment<<EOF"
                echo "Plan completed but no recognisable summary was found in the logs."
                echo "EOF"
              } >> "$GITHUB_OUTPUT"
            fi
            exit 0
          fi

          echo "has_changes=true" >> "$GITHUB_OUTPUT"

          # Build a combined summary from all stacks that reported changes
          TOTAL_ADD=0; TOTAL_CHANGE=0; TOTAL_DESTROY=0
          while IFS= read -r line; do
            add=$(echo "$line" | grep -oP '(\d+) to add' | grep -oP '\d+')
            chg=$(echo "$line" | grep -oP '(\d+) to change' | grep -oP '\d+')
            dst=$(echo "$line" | grep -oP '(\d+) to destroy' | grep -oP '\d+')
            TOTAL_ADD=$(( TOTAL_ADD + ${add:-0} ))
            TOTAL_CHANGE=$(( TOTAL_CHANGE + ${chg:-0} ))
            TOTAL_DESTROY=$(( TOTAL_DESTROY + ${dst:-0} ))
          done <<< "$PLAN_LINES"

          STACK_COUNT=$(echo "$PLAN_LINES" | wc -l)
          SUMMARY="${TOTAL_ADD} to add, ${TOTAL_CHANGE} to change, ${TOTAL_DESTROY} to destroy (across ${STACK_COUNT} stack(s))"

          # Extract the first block of planned actions for the collapsible detail
          START_LINE=$(grep -n "Terraform will perform the following actions:" "$CLEAN_LOG" | head -n 1 | cut -d: -f1 || true)
          if [[ -n "$START_LINE" ]]; then
            SNIPPET=$(sed -n "${START_LINE},$((START_LINE + 220))p" "$CLEAN_LOG")
          else
            SNIPPET=$(tail -n 220 "$CLEAN_LOG")
          fi

          SNIPPET=$(printf '%s' "$SNIPPET" | sed 's/```/` ` `/g')
          if [[ ${#SNIPPET} -gt 12000 ]]; then
            SNIPPET="${SNIPPET:0:12000}"
            SNIPPET+=$'\n(truncated, see workflow logs for complete plan)'
          fi

          {
            echo "plan_comment<<EOF"
            echo "**Summary:** ${SUMMARY}"
            echo
            echo "<details><summary>Show plan details</summary>"
            echo
            echo "\`\`\`hcl"
            echo "$SNIPPET"
            echo "\`\`\`"
            echo
            echo "</details>"
            echo "EOF"
          } >> "$GITHUB_OUTPUT"

      - name: Install bats-core
        if: inputs.command == 'apply'
        uses: bats-core/bats-action@4.0.0

      - name: Run Integration Tests
        if: inputs.command == 'apply' && (inputs.environment_name == 'dev' || inputs.environment_name == 'test')
        shell: bash
        working-directory: ./infra-ai-hub
        env:
          TEST_ENV: ${{ inputs.environment_name }}
          HTTP_PROXY: "http://127.0.0.1:8118"
          HTTPS_PROXY: "http://127.0.0.1:8118"
          NO_PROXY: "management.azure.com,login.microsoftonline.com,graph.microsoft.com,registry.terraform.io,releases.hashicorp.com,github.com,objects.githubusercontent.com"
        run: |
          set -euo pipefail

          echo "=== Running Integration Tests (env-aware harness) ==="
          cd ../tests/integration
          chmod +x ./run-tests.sh
          ./run-tests.sh --env "${TEST_ENV}"
