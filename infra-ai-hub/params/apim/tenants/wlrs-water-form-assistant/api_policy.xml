<policies>
    <inbound>
        <base />
        <!-- Tenant identification -->
        <set-header name="X-Tenant-Id" exists-action="override">
            <value>wlrs-water-form-assistant</value>
        </set-header>

        <!-- ================================================================== -->
        <!-- TRACKING DIMENSIONS                                               -->
        <!-- Extract session, user, and app IDs for analytics                 -->
        <!-- ================================================================== -->
        <include-fragment fragment-id="tracking-dimensions" />

        <!-- Detect streaming mode for OpenAI requests -->
        <set-variable name="isStream" value="@{
            var stream = context.Request.Url.Query.GetValueOrDefault("stream", "");
            if (string.IsNullOrEmpty(stream)) {
                try {
                    var body = context.Request.Body?.As<JObject>(preserveContent: true);
                    stream = body?["stream"]?.ToString() ?? "false";
                } catch { stream = "false"; }
            }
            return stream.ToLower();
        }" />

        <!-- Token rate limiting: 10,000 TPM per subscription for this tenant -->
        <!-- Protects backend from token exhaustion, returns 429 when exceeded -->
        <llm-token-limit
            counter-key="@(context.Subscription.Id)"
            tokens-per-minute="10000"
            estimate-prompt-tokens="true"
            remaining-tokens-variable-name="remainingTokens"
            remaining-tokens-header-name="x-ratelimit-remaining-tokens"
            tokens-consumed-variable-name="tokensConsumed" />

        <!-- Path-based routing to appropriate backend service -->
        <choose>
            <!-- Document Intelligence requests: match documentintelligence, formrecognizer, or documentModels in path -->
            <when condition="@(context.Request.Url.Path.ToLower().Contains("documentintelligence") || context.Request.Url.Path.ToLower().Contains("formrecognizer") || context.Request.Url.Path.ToLower().Contains("documentmodels"))">
                <set-backend-service backend-id="wlrs-water-form-assistant-docint" />
                <set-variable name="backendId" value="wlrs-water-form-assistant-docint" />
                <set-variable name="routeLocation" value="canadacentral" />
                <set-variable name="routeName" value="document-intelligence" />
                <set-variable name="deploymentName" value="docint" />
                <authentication-managed-identity resource="https://cognitiveservices.azure.com" output-token-variable-name="msi-access-token" ignore-error="false" />
                <set-header name="Authorization" exists-action="override">
                    <value>@("Bearer " + (string)context.Variables["msi-access-token"])</value>
                </set-header>
                <set-header name="api-key" exists-action="delete" />
            </when>
            <!-- OpenAI requests: /openai/* -->
            <when condition="@(context.Request.Url.Path.ToLower().Contains("openai"))">
                <!-- ============================================================ -->
                <!-- INTELLIGENT ROUTING (when multiple backends available)       -->
                <!-- Uncomment below to enable priority-based routing             -->
                <!-- ============================================================ -->
                <!--
                <set-variable name="routes" value="@{
                    return new JArray(
                        new JObject {
                            [\"name\"] = \"canadacentral-primary\",
                            [\"backend-id\"] = \"wlrs-water-form-assistant-openai\",
                            [\"location\"] = \"canadacentral\",
                            [\"priority\"] = 1,
                            [\"isThrottling\"] = false
                        },
                        new JObject {
                            [\"name\"] = \"eastus-secondary\",
                            [\"backend-id\"] = \"wlrs-water-form-assistant-openai-eastus\",
                            [\"location\"] = \"eastus\",
                            [\"priority\"] = 2,
                            [\"isThrottling\"] = false
                        }
                    );
                }" />
                <include-fragment fragment-id="intelligent-routing" />
                <set-backend-service backend-id="@((string)context.Variables[\"backendId\"])" />
                -->
                
                <!-- Single backend configuration (current) -->
                <set-backend-service backend-id="wlrs-water-form-assistant-openai" />
                <set-variable name="backendId" value="wlrs-water-form-assistant-openai" />
                <set-variable name="routeLocation" value="canadacentral" />
                <set-variable name="routeName" value="openai" />
                <set-variable name="deploymentName" value="@{
                    var path = context.Request.Url.Path;
                    var match = System.Text.RegularExpressions.Regex.Match(path, @"/deployments/([^/]+)/");
                    return match.Success ? match.Groups[1].Value : "unknown";
                }" />
                <authentication-managed-identity resource="https://cognitiveservices.azure.com" output-token-variable-name="msi-access-token" ignore-error="false" />
                <set-header name="Authorization" exists-action="override">
                    <value>@("Bearer " + (string)context.Variables["msi-access-token"])</value>
                </set-header>
                <set-header name="api-key" exists-action="delete" />
            </when>
            <!-- AI Search requests: /ai-search/* -->
            <when condition="@(context.Request.Url.Path.ToLower().Contains("ai-search"))">
                <set-backend-service backend-id="wlrs-water-form-assistant-ai-search" />
                <set-variable name="backendId" value="wlrs-water-form-assistant-ai-search" />
                <set-variable name="routeLocation" value="canadacentral" />
                <set-variable name="routeName" value="ai-search" />
                <set-variable name="deploymentName" value="ai-search" />
                <!-- Strip /ai-search prefix from path before forwarding to backend -->
                <!-- Path format: ai-search/{rest} -> /{rest} -->
                <rewrite-uri template="@{
                    var path = context.Request.Url.Path;
                    var searchIndex = path.ToLower().IndexOf("ai-search");
                    if (searchIndex >= 0) {
                        return "/" + path.Substring(searchIndex + 9).TrimStart('/');
                    }
                    return path;
                }" copy-unmatched-params="true" />
                <authentication-managed-identity resource="https://search.azure.com" output-token-variable-name="msi-access-token" ignore-error="false" />
                <set-header name="Authorization" exists-action="override">
                    <value>@("Bearer " + (string)context.Variables["msi-access-token"])</value>
                </set-header>
                <set-header name="api-key" exists-action="delete" />
            </when>
            <!-- Default: Return 404 for unmatched paths -->
            <otherwise>
                <return-response>
                    <set-status code="404" reason="Not Found" />
                    <set-header name="Content-Type" exists-action="override">
                        <value>application/json</value>
                    </set-header>
                    <set-body>{"error":{"code":"NotFound","message":"The requested path is not supported by this API."}}</set-body>
                </return-response>
            </otherwise>
        </choose>
    </inbound>
    <backend>
        <base />
    </backend>
    <outbound>
        <base />
        <!-- OpenAI usage logging and streaming metrics -->
        <choose>
            <when condition="@(context.Request.Url.Path.ToLower().Contains("openai") && context.Response.StatusCode == 200)">
                <!-- For non-streaming: capture response body and log usage -->
                <choose>
                    <when condition="@(context.Variables.GetValueOrDefault<string>("isStream", "false") != "true")">
                        <set-variable name="responseBody" value="@(context.Response.Body.As<JObject>(preserveContent: true))" />
                        <include-fragment fragment-id="openai-usage-logging" />
                    </when>
                    <otherwise>
                        <!-- Streaming: use streaming metrics fragment -->
                        <include-fragment fragment-id="openai-streaming-metrics" />
                    </otherwise>
                </choose>
            </when>
        </choose>
    </outbound>
    <on-error>
        <base />
    </on-error>
</policies>
